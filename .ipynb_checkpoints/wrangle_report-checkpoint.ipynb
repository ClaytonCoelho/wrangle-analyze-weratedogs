{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to put in practice what I learned in data wrangling.\n",
    "\n",
    "The dataset in project is a twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10.\n",
    "\n",
    "My goal in project is wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations through the following processes:\n",
    "- Gathering Data\n",
    "- Assessing Data\n",
    "- Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "\n",
    "Os dados desse projetos foram fornecidos de 3 formas diferentes:\n",
    "\n",
    "- The WeRateDogs Twitter archive `twitter_archive_enhanced.csv`, that was provided from manually by Udacity.\n",
    "- The tweet image predictions, i.e., what breed of dog (or other object, animal, etc.) is present in each tweet according to a neural network. The file `image_predictions.tsv` is hosted on Udacity's servers URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv.\n",
    "- The additional information was collected directly from Twitter via API, to increase data for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `twitter_archive_enhanced.csv` file had to be downloaded manually on the Udacity plataform, saved to the local project folder and imported into Jupyter Notebook using the python pandas library.\n",
    "\n",
    "The `image_predictions.tsv` file downloaded programmatically directly to Jupyter Notebook using the python requests library, saving locally and then importing it with pandas.\n",
    "\n",
    "Additional information about the tweets was acquired through the **Twitter API**, using python's **Tweepy** library. Here I had to register at https://developer.twitter.com/ to purchase access tokens.\n",
    "\n",
    "The data collection via API was performed inside the Jupyter Notebook and stored in a file in **JSON** format. It took 1943.86 seconds to run and I had 2331 tweet information successfully and 25 failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Data\n",
    "\n",
    "After gathering the data and storing them in DataFrames into Jupyter Notebook, start the process of evaluating the data to identify possible problems with it.\n",
    "\n",
    "I performed visual assessment, but here it is more difficult to arrive at good analyzes because the datasets were large.\n",
    "\n",
    "Then I started the evaluation programmatically, using the functions of the pandas library to identify possible problems.\n",
    "\n",
    "With the analysis I arrived at the problems below that need to be treated:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues\n",
    "- df_twitter_archive:\n",
    "    - Column `name` with some dogs have 'None' as a name, or 'a'.\n",
    "    - Erroneous datatypes (`timestamp`)\n",
    "    - Nulls values in columns `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id`, `retweeted_status_timestamp` and `expanded_urls`.\n",
    "    - Values in inconsistent in columns `rating_denominator` and `rating_numerator`.\n",
    "    - Nulls represented as `None` (`doggo`, `floofer`, `pupper` and `puppo`).\n",
    "    - Values in column `retweeted_status_id` indicates retweeted.\n",
    "    - Nulls values in columns `retweet_count` and `favorite_count`.\n",
    "- df_image_prediction:\n",
    "    - Duplicated in column `jpg_url` indicates retweeted.\n",
    "    - There are images that have been classified as non-dogs.\n",
    "\n",
    "### Tidiness Issues\n",
    "- df_twitter_archive:\n",
    "    - The last four columns all relate to the same variable (dogoo, floofer, pupper, puppo).\n",
    "- df_image_prediction:\n",
    "    - This data set is part of the same observational unit as the data in the df_twitter_archive.\n",
    "- df_tweets_info_additional:\n",
    "    - The id column with name different from the other tables.\n",
    "    - This data set is part of the same observational unit as the data in the df_twitter_archive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "\n",
    "After raising the problems that needed to be addressed, I entered the cleaning data phase to carry out the necessary corrections.\n",
    "\n",
    "In this step I used the process below for each problem:\n",
    "- Define: Describe what needs to be done to resolve the problem.\n",
    "- Code: Write and run the code to correct the problem.\n",
    "- Test: Test to validate that we were successful in the proposed solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
